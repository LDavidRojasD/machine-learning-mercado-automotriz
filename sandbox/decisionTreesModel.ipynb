{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Modelo de árbol de decisión con aprendizaje que permite clasificar a los vehículos\n","# en baratos y caros usando la mediana de los precios como punto de corte\n","# , utilizando el archivo 'ML_cars.csv'.\n","# By Rafael Balestrini\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import entropy\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier, plot_tree\n","from sklearn.metrics import accuracy_score\n","from misFunciones import impurezaGini\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('../datasource/DatasetForML.csv')\n","df.columns"]},{"cell_type":"markdown","metadata":{},"source":["### Entropía"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calcular la entropía de cada variable en el DataFrame\n","entropias = {}\n","for columna in df.columns:\n","    entropias[columna] = entropy(df[columna].value_counts(normalize=True), base=2)\n","\n","# Ordenar las entropías de mayor a menor\n","entropiasOrdenadas = sorted(entropias.items(), key = lambda x: x[1], reverse = True)\n","\n","# Imprimir los resultados ordenados\n","for variable, entropia in entropiasOrdenadas:\n","    print(f'{variable} -> entropía: {entropia}')"]},{"cell_type":"markdown","metadata":{},"source":["### Interpretación de la Impureza GINI\n","La impureza de gini se puede definir informalmente como la probabilidad de clasificar incorrectamente a una observación dado un conjunto de datos. A menor impureza mejor es el clasificador. La mayor impureza es 0.5 por la tanto el peor clasificador."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["variables = df.drop('price_category', axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ginis = {}\n","for variable in variables:\n","    ginis[variable] = impurezaGini(variable, \"price_category\", df)\n","\n","# Ordenar las impurezas gini de menor a mayor\n","ginisOrdenadas = sorted(ginis.items(), key = lambda x: x[1])\n","\n","# Imprimir los resultados ordenados\n","for variable, gini in ginisOrdenadas:\n","    print(variable, '-> impureza: %0.4f' % gini)"]},{"cell_type":"markdown","metadata":{},"source":["### Variables predictoras y la variable objetivo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 'X' es todo el dataframe original pero sin la columna 'price_category'. Es la matriz \n","# con las variables independientes o predictoras o también llamadas características\n","# X = df.drop('price_category', axis = 1) # (205, 61)\n","# X = df[['cylindernumber']]\n","X = df[['curbweight', 'highwaympg', 'citympg']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# 'y' es un n-arreglo unidimensional de Pandas que contiene las\n","# variables dependientes o etiquetas o también llamadas objetivos\n","                         # 0    103    Barato\n","y = df['price_category'] # 1    102    Caro\n","                         # (205,) dtype: int64"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Profundidad máxima del árbol\n","proMax = 4"]},{"cell_type":"markdown","metadata":{},"source":["### Datos de entrenamiento y pruebas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#criterio = 'entropy'\n","criterio = 'gini'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dividimos la matriz X en conjuntos de entrenamiento y prueba\n","# X_train es un dataframe con el 80% de X para entrenar\n","# X_test es un dataframe con el 20% de X para las pruebas\n","# y_train es una serie con el 80% de y para entrenar\n","# y_test es una serie con el 20% de y para las pruebas\n","XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","\n","# Creamos el modelo de árbol de decisión\n","modeloArbol = DecisionTreeClassifier(criterion = criterio, max_depth = proMax)  # Profundidad máxima \n","#modeloArbol = DecisionTreeClassifier()  # Profundidad máxima todas\n","\n","# Ponemos a entrenar al modelo\n","modeloArbol.fit(XTrain, yTrain)\n","\n","# Aplicamos la clasificación a los datos de prueba\n","yPred = modeloArbol.predict(XTest)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluamos el rendimiento del modelo\n","accuracy = accuracy_score(yTest, yPred)\n","accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Graficamos el árbol\n","plt.figure(figsize=(15, 10))\n","plot_tree(modeloArbol, filled=True, feature_names=X.columns, class_names=['barato', 'caro'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Calibración de hiperparámetro"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Crear un DataFrame vacío para almacenar los resultados\n","accuracies = pd.DataFrame(columns = [\n","    'Variable', 'maxDepth 1', 'maxDepth 2', 'maxDepth 3', 'maxDepth 4',\n","    'maxDepth 5', 'maxDepth 6', 'Metodo'])\n","\n","variables = ['curbweight', 'carlength', 'horsepower', 'carheight', 'wheelbase', 'price_category']\n","\n","for variable in variables:\n","    maxDepths = []\n","    for depth in range(accuracies.shape[1] - 2):\n","        X = df[[variable]]\n","        \n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","        \n","        # Creamos el modelo de árbol de decisión\n","        modeloArbol = DecisionTreeClassifier(criterion = criterio, max_depth = depth + 1)  # Profundidad máxima\n","        \n","        # Ponemos a entrenar al modelo        \n","        modeloArbol.fit(X_train, y_train)\n","        \n","        # Aplicamos la clasificación a los datos de prueba\n","        y_pred = modeloArbol.predict(X_test)\n","\n","        # Evaluamos el rendimiento del modelo\n","        accuracy = accuracy_score(y_test, y_pred)\n","        #print(f'accuracy={accuracy}')\n","        maxDepths.append(accuracy) \n","\n","        if depth == proMax - 1:\n","            # Graficamos el árbol\n","            plt.figure(figsize=(15, 10))\n","            plot_tree(modeloArbol, filled=True, feature_names=X.columns, class_names=['barato', 'caro'])\n","            plt.show()\n","\n","    #print(variable, maxDepths)\n","    # Agregar el resultado al DataFrame\n","    accuracies.loc[len(accuracies)] = [variable, maxDepths[0], maxDepths[1], maxDepths[2],\n","                                       maxDepths[3], maxDepths[4], maxDepths[5], 'gini']  \n","\n","# Mostrar el DataFrame resultante\n","accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluamos el rendimiento del modelo\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Precisión del modelo:\", accuracy)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
